---
layout: post
title: S3 | Amazon Web Services Notes 
---

Simple Storage Service, S3 provides developers and IT teams with secure, durable, high-scalable object storage. Amazon S3 is easy to use, with a simple web services interface to store and retrieve any amount of data from anywhere on the web. It is for files not for operating systems and DB.

* S3 is a safe place to store your files.
* It is Object-based storage.
* The data is spread across multiple devices and facilities. 

### Notes
#### S3 The basics

- S3 is Object-based - i.e. allows you to upload files,
- files can be from 0 bytes to 5 TB
- there is unlimited storage (no need to predict)
- files are store in buckets (similar to a folder)
- S3 is a universal name space. That is, names must be unique globally. Similar to DNS or Internet address. 
- when you upload a file to S3 you will receive a HTTP 200 code if the upload was successful (only CLI or API)
- built for 99.99% availability for the S3 platform. Amount of time when service is available. 
- Amazon Guarantee 99.9% availability,
- Amazon guarantees 99.9(9)% durability for S3. Really safe place to store your data. (11 x 9s)
- Tiered Storage Available,
- Life-cycle Management
- Versioning,
- Encryption,
- Secure your data - Access control list and policies. 

#### Data Consistency Model for S3

- Read after Write consistency for PUTS of new Objects (first time, as soon as you add object the file is available to read)
- Eventual Consistency for overwrite PUTS and DELETES can take some time to propagate( **not going to be immediate**)

#### S3 is a simple Key-value Store

S3 is **Object based**. Object consist of the following:
- Key - name of the object, filename,
- Value - data, sequence o bytes, 
- Version ID ( important for versioning), allows to rollback or so,
- matadata, you can add your own matadata,
- sub-resources - bucket-specific configurations - bucket policies, access control lists, 
Cross Origin Resources Sharing (CROS), Transfer Acceleration. 

#### S3 - Storage Tiers/Classes

-S3 : 99.99% availability, 99,9 (9) durability - stored redundantly across multiple devices in multiple facilities, and is designed to sustain the loss of 2 facilities concurrently, 

- S3 IA (Infrequently Accessed) For data that is accessed less frequently but requires rapid access when needed. Lower fee than S3, but you are charged a retrieval fee. 

- S3 - One Zone IA: Same as IA however data is stored in a single AZ only, still 99,9(9) durability, but only 99,5% availability. Cost is 20% less than S3 -IA

- Reduced Redundancy Storage - designed to provide 99.99% durability and 99,99% availability of objects over a given year. used for data that can be recreated if lost e.g. thumbnails. Starting to disappear from AWS documentation but may still feature in exam)

- Glacier - very cheap, but used for archival only. Optimized for data that is infrequently accessed and it takes 3-5 hours to restore from Glacier. Suitable for historical files. 

#### S3 - Charges

- Storage per GB, 
- request (Get, Put, Copy)
- storage management pricing - inventory , analytics, and Object tags
- data management pricing - data transferred out of S3 (is free to transfer to S3 )
- transfer acceleration - use of CloudFront to optimize transfers,

#### S3 - Security

By default all newly creates buckets are PRIVATE.
You can set up access control to your buckets using:
- Bucket Policies - applied at a bucket level (cant applied to individual object) - written in JSON. 
- Access Control List - applied at an object level (applied at an object level)

S3 bucket can be configured to create access logs, which log all requests made to the S3 bucket. These logs can be written to another bucket. 


### S3 - LAB - Policies

You can easily generate policies by AWS policy generator. Policies are written in JSON. 

### S3 - Encryption (two methods)

There are two types of encryption.

#### In transit 
Encrypting data you are sending to and from your bucket. (SSL/TLS)
We use HTTPS protocol to upload and download. Encryption In-transit encrypt the data over the network. 

#### At Rest 

Server Side Encryption:
- S3 Managed Keys - **SSE-S3** - S3 menages the keys,
- AWS Key Management Service, Managed Keys, S3-KMS - Amazon menages the keys 
- Server Side Encryption with Customer Provided Keys - SSE-C - customer menages the keys

Client Side Encryption
You can chose encryption method. You encrypt your file locally before you upload it to S3.


**Exam tip** - If you want to enforce the use of encryption for your files stored in S3, use an S3 Bucket Policy to deny all PUT request that don't include the *x-amz-server-side-encryption parameter* in the request header. 


### S3 - LAB - Set up Encryption On An S3 Bucket

Set up encryption using policies, add condition to not allow PUT when String doesn't contain x-amz-derver-side-encryption. Try to upload files on different way, encrypted non-encrypted .

### S3 - LAB - CORS Configuration - Cross-Origin Resource Sharing

In a nutshell, it allowing code that is in one S3 bucket to access or reference code which is in another S3 bucket (one resource to access another resource).

Enable Static website hosting on both S3 buckets and **use endpoint website URL** to check config. 

CROS configuration is really good idea to organize your website. You can store image files in one bucket, java scripts in another bucket, plain HTML in another bucket and then configure CROS to allow one bucket to have access to another bucket.

**Exam tip** - remember to enable CORS you'll need to enable it from the bucket that contains resources that will being shared 


### S3 - Performance Optimization

S3 is designed to support very high request rates. however, if your S3 bucket are routinely receiving > 100 PUT/LIST/DELETE or > 300 GET requests per second, then there are some best practice guidelines that will help optimized S3 performance. 

The guidance is based on the type of workload you are running:

**Get-Intensive Workloads** - use CloudFront content delivery service to get bes performance. CloudFront will cache your most frequently accessed objects and will reduce latency for your GET request.

**Mixed Request Type Workloads** - a mix of GET, PUT, DELETE, GET bucket, the key names you use for your object can impact performance for intensive workloads. 
- S3 uses the key name to determine which partition on object will be stored in 
- The use of sequential key names e.g. names prefixed withe a time stamp or alphabetical sequence increases the likelihood of having multiple objects stored on the same partition. 
- for heavy workloads this can cause I/O issues and contention
- by using a random prefix to key names, you can force S3 to distribute your keys across multiple partitions, distributing the I/O workloads. 

**Exam-tip** - Remember the 2 main approaches to Performance Optimization for S3. 

------------
*Notes based mainly on Cloud Guru Course - [AWS Certified Developer](https://acloud.guru/learn/aws-certified-developer-associate-june-2018) and [AWS Whitepapers](https://aws.amazon.com/whitepapers/)*